# RNN 장기 의존성 Long Term Dependency 문제점해결

"I grew up in France... I speak fluent French.(나는 프랑스에서 자라났어... 나는 프랑스어를 유창하게 해)\"라는 문장에서 마지막 단어
French(프랑스어)를 예측. 최근 정보를 기반으로 예측 모델은 다음 단어가 아마도 언어의 한 종류라고 예측될 것입니다.
그렇다면, 이 예측 모델은 \"I grew up in France(나는 프랑스에서 자라났다)\"에서 프랑스라는 문맥이 필요하게 됩니다. 
실제로 \"I grew up in France(프랑스에서 자라났다)\"는 표현과 \"I speak fluent *** (나는 *** 언어를 유창하게 한다)\"라는 
표현의 위치가 멀어지는 문제는 아주 빈번하게 발생합니다."

구성요소
메모리 셀은 그냥 전체적인 큰 구조 (총 구조)라고 생각하면 된다.
셀 스테이트는 전체적인 처리 과정이라고 보면 된다. 그림에 보이는 맨 윗줄에 해당한다.
게이트는 내부적으로 시그모이드 함수를 통해 흐름을 담당한다. 셀 스테이트 과정에 포함되어있다고 생각하면 이해가 편하다.

Gate 역할
셀 스테이트에 있는 Gate는 통해서 기존 정보를 버릴 것인지, 기억할 것인지를 선택한다.
또한 Gate는 새로운 정보를 추가하거나 삭제하는 기능도 담당한다.
이러한 Gate는 선택적으로 데이터가 삭제 및 추가가 되도록 하는 장치이며 시그모이드 함수로 이루어져있다.
Gate는 (시그모이드를 이용해서) 0이 나오면 버리거나 삭제 또는 아무것도 안하고, 1이 나오면 기억하거나 추가하거나 계산한다.
이는 0 = false, 1 = true를 연상하면 쉽게 이해가능한 부분이다.

셀 스테이트 역할
셀 스테이트는 크게 3가지 게이트를 통해서 흐름을 제어한다.
자세한 내용 링크 : https://brunch.co.kr/@chris-song/9
1. 셀 스테이트에서 어떤 정보를 버릴지 선택하는 과정
2. 새로운 정보가 셀 스테이트에 저장될지 결정하는 단계
3. 어떤 출력값을 출력할지 결정하는 단계

LSTM은 위와 같은 방식으로 과거의 정보들을 꾸준히 업데이트하여 장기 의존성을 해결했다.
LSTM은 가중치를 곱셈으로 처리하지 않고 덧셈으로 처리하기 때문에 Gradient Vanishing 문제를 해결할 수 있었다.
[출처] 딥러닝 (DeepLearning) - 순환 인공 신경망 (RNN, LSTM)|작성자 하면한다
