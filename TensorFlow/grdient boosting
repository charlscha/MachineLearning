그래디언트부스팅
약한 학습기(weak learner)를 결합 강한 학습기로 바꾸는것 행위

가중치를추가
Y = M(X) + W

또다른 가중치 추가
W = H(X) + W2

대입하면
Y = M(X) + H(X) + W2

결론
Y = 알파*M(X) + 베타*H(X) + W

부스팅 모델은 각각의 M(X) , H(X)에 가중치를 적절하게 조절


예를 들어


손실함수가 1/2( y - fi(x) )^ 일경우 이때 기울기는 y -fi
이때 모델 함수 (fi)에 잔차 (y-fi)를 더하면 당연히 y가 나옴 의미가없음
여기서 그래디언트부스팅은 

현재 상태의 미분값(기울기)을 다음번 모델 (i+1)의 타겟을 놓고 값을 구함

결론 >>

손실함수 : 1/2( y - fi(x) )^
step1 : f1
	미분 값은 : y-f1(x)
step2 : f2
	미분 값은 : y-f2(x)

f2+( y-f1(x) )

