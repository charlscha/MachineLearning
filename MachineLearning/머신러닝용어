참고사이트 : http://hellogohn.com/post_one18


딥러닝과 머신러닝의 차이는 무엇인가??



저도 공부하면서 정리해봤습니다. ppt 랑 같이 보시면 더 좋을 것 같습니다.





-인공지능 :       수학적으로 표현할 수 없었떤 복잡한 인간의 두뇌를 데이터를 기반으로 흉내내다.

    위키백과 출처 : 인공지능(人工知能, 영어: artificial intelligence, AI)은 철학적으로 인간성이나 지성을 갖춘 존재, 혹은 시스템에 의해 만들어진 지능, 즉 인공적인 지능을 뜻한다. 일반적으로 범용 컴퓨터에 적용한다고 가정한다. 이 용어는 또한 그와 같은 지능을 만들 수 있는 방법론이나 실현 가능성 등을 연구하는 과학 분야를 지칭하기도 한다.




-머신러닝 :       러닝 == 학습이다. 인공지능이 점점 똑똑해진다. Data가 늘어날수록 인공지능 알고리즘이 학습한다. 

    __위키백과 출처__ : 머신 러닝(영어: machine learning) 또는 기계 학습(機械 學習)은 인공 지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야를 말한다. 가령, 기계 학습을 통해서 수신한 이메일이 스팸인지 아닌지를 구분할 수 있도록 훈련할 수 있다.
기계 학습의 핵심은 표현(representation)과 일반화(generalization)에 있다. 표현이란 데이터의 평가이며, 일반화란 아직 알 수 없는 데이터에 대한 처리이다. 이는 전산 학습 이론 분야이기도 하다. 다양한 기계 학습의 응용이 존재한다. 문자 인식은 이를 이용한 가장 잘 알려진 사례이다.



    __나무위키 출처__ : 기계학습의 가장 그럴듯한 정의는 다음과 같다. 이는 "Machine Learning" 책을 지은 CMU의 교수 Tom M. Mitchell이 제시한 것이다.

"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E"


즉, 어떠한 태스크(T)에 대해 꾸준한 경험(E)을 통하여 그 T에 대한 성능(P)를 높이는 것, 이것이 기계학습이라고 할 수 있다. 

정의에서 알 수 있듯이, 기계학습에서 가장 중요한 것은 E에 해당하는 데이터이다. 좋은 품질의 데이터를 많이 가지고 있다면 보다 높은 성능을 끌어낼 수 있다.



    요약 : 기존 데이터들을 평가하여 -> 향후 데이터를 평가한다. 





-머신러닝의 기능 : 

    __ 나무위키 출처__ : 
분류 (Classification) : 주어진 입력 x의 레이블 y를 추정해내는 것
y는 1/0의 이진값이거나 혹은 확률이나 실수값으로 주어질 수 있다.



 ex ) 동물 사진을 x 값으로 주었을 때, 고양이가 아닌지 맞는지에 관하여 True or False 를 반환한다.

     혹은 동물 사진을 x 값으로 주었을 때, 고양이일 확률값을 반환하거나 고양이라는 실수를 반환한다. 



군집화 (Clustering) : 주어진 입력 x와 비슷한 입력들의 군집(cluster)을 추정해내는 것



        ex ) 내가 키우고 있는 고양이의 사진 x 를 받는다. 그러면 DB 에 동물 사진들이 쌓여 있다고 하자.
            입력 x 즉, 고양이사진을 받으면 고양이들을 추정해낸다. 


-머신러닝의 3가지 타입

 (1) Supervised Learning ( 지도학습 ) = 정답이 주어지고 문제풀이가 쉽다.

    __위키백과 출처__ : 지도 학습 (영어: Supervised Learning)은 훈련 데이터(Training Data)로부터 하나의 함수를 유추해내기 위한 기계 학습(Machine Learning)의 한 방법이다. 훈련 데이터는 일반적으로 입력 객체에 대한 속성을 벡터 형태로 포함하고 있으며 각각의 벡터에 대해 원하는 결과가 무엇인지 표시되어 있다. 이렇게 유추된 함수 중 연속적인 값을 출력하는 것을 회귀분석(Regression)이라 하고 주어진 입력 벡터가 어떤 종류의 값인지 표식하는 것을 분류(Classification)라 한다. 지도 학습기(Supervised Learner)가 하는 작업은 훈련 데이터로부터 주어진 데이터에 대해 예측하고자 하는 값을 올바로 추측해내는 것이다. 이 목표를 달성하기 위해서는 학습기가 "알맞은" 방법을 통하여 기존의 훈련 데이터로부터 나타나지 않던 상황까지도 일반화하여 처리할 수 있어야 한다. 

    __나무위키 출처__ :  사람이 교사로써 각각의 입력(x)에 대해 레이블(y)을 달아놓은 데이터를 컴퓨터한테 주면 컴퓨터가 그것을 학습하는 것이다. 사람이 직접 개입하므로 정확도가 높은 데이터를 사용할 수 있다는 장점이 있다. 대신에 사람이 직접 레이블을 달아야 하므로 인건비 문제가 있고, 구할 수 있는 데이터양도 적다는 문제가 있다. 크게 분류(Classification)과 회귀(Regression) 으로 나눌 수 있다.

분류(Classification): 레이블 y가 
이산적(Discrete)
인 경우 즉, y가 가질 수 있는 값이 [0,1,2 ..]와 같이 유한한 경우 분류, 혹은 인식 문제라고 부른다. 일상에서 가장 접하기 쉬우며, 연구가 많이 되어있고, 기업들이 가장 관심을 가지는 문제 중 하나다. 아래와 같은 예시가 있다.

주차게이트에서 번호판 인식: 요새 주차장들은 티켓을 뽑지 않고, 차량 번호판을 찍어서 글자를 인식한다. x가 이미지 픽셀 값들이고, y가 글자인 경우.

페이스북이나 구글 포토의 얼굴 인식: 페이스북에 사진을 올리면 친구 얼굴 위에 이름이 자동으로 달리고는 하는데, 이것 역시 기계학습을 이용한 것. x가 이미지 픽셀, y가 사람 이름인 경우.

음성 인식: 음성 wav 파일에 대해서 해당 wav 부분이 어떤 음절인지를 인식하는 것. 애플 시리, 구글 보이스 등에서 사용된다(질문에 대해서 답해주는 부분 말고, 인식 부분만). x가 음성 파형, y가 음절.



회귀(Regression): 레이블 y가 실수인 경우 회귀문제라고 부른다. 보통 엑셀에서 그래프 그릴 때 많이 접하는 바로 그것이다. 데이터들을 쭉 뿌려놓고 이것을 가장 잘 설명하는 직선 하나 혹은 이차함수 곡선 하나를 그리고 싶을 때 회귀기능을 사용한다. 잘 생각해보면 데이터는 입력(x)와 실수 레이블(y)의 짝으로 이루어져있고, 새로운 임의의 입력(x)에 대해 y를 맞추는 것이 바로 직선 혹은 곡선이므로 기계학습 문제가 맞다.



    요약 : 데이터들로 부터 하나의 함수룰 유추한다. -> 예측하고자 하는 값을 올바로 추측 (사람이 식을 설정하는듯)
    의문 : 선형함수로 추정하면 정확도가 부정확할 것 같다. 그림만 봐도 그럴 것 같고.



 (2) UnSupervised Learning ( 자율 학습 ) = 미지수 2개 식 1개 같은형태.
       특정 조건이 있을때만 정답이 주어질 수 있다. 문제풀이가 어렵다.

    __위키백과 출처__ : 자율 학습(Unsupervised Learning)은 기계 학습의 일종으로, 데이터가 어떻게 구성되었는지를 알아내는 문제의 범주에 속한다. 이 방법은 지도 학습(Supervised Learning) 혹은 강화 학습(Reinforcement Learning)과는 달리 입력값에 대한 목표치가 주어지지 않는다.
자율 학습은 통계의 밀도 추정(Density Estimation)과 깊은 연관이 있다. 이러한 자율 학습은 데이터의 주요 특징을 요약하고 설명할 수 있다.



    __나무위키 출처__ :  사람 없이 컴퓨터가 스스로 레이블 되어 있지 않은 데이터에 대해 학습하는 것. 즉 y없이 x만 이용해서 학습하는 것이다. 정답이 없는 문제를 푸는 것이므로 학습이 맞게 됐는지 확인할 길은 없지만, 인터넷에 있는 거의 모든 데이터가 레이블이 없는 형태로 있으므로 앞으로 기계학습이 나아갈 방향으로 설정되어 있기도 하다. 군집화(Clustering)이 대표적인 예다.

군집화(Clustering): 데이터가 쭉 뿌려져 있을 때 레이블이 없다고 해도 데이터간 거리에 따라 대충 두 세개의 군집으로 나눌 수 있다. 이렇게 x만 가지고 군집을 학습하는 것이 군집화이다.

분포 추정(Underlying Probability Density Estimation): 군집화에서 더 나아가서, 데이터들이 쭉 뿌려져 있을 때 얘네들이 어떤 확률 분포에서 나온 샘플들인지 추정하는 문제이다.





    요약 : 식이 없고, 주어진 데이터 값이나 입력값으로만 답을 유추해 낸다. 컴퓨터가 식을 세운다는 점에서 굉장한 기술 같아 보인다. 


(3) Reinforcement Learning ( 강화 학습 ) = (정답이 아닌) reward 가 주어진다. 

    __위키백과 출처__ : 강화 학습(Reinforcement learning)은 기계 학습이 다루는 문제 중에서 다음과 같이 기술 되는 것을 다룬다. 어떤 환경을 탐색하는 에이전트가 현재의 상태를 인식하여 어떤 행동을 취한다. 그러면 그 에이전트는 환경으로부터 포상을 얻게 된다. 포상은 양수와 음수 둘 다 가능하다. 강화 학습의 알고리즘은 그 에이전트가 앞으로 누적될 포상을 최대화 하는 일련의 행동으로 정의되는 정책을 찾는 방법이다.

    __나무위키 출처__ :  위의 두 문제의 분류는 지도의 여부에 따른 것이었는데, 강화학습은 조금 다르다. 강화학습은 현재의 상태(State)에서 어떤 행동(Action)을 취하는 것이 최적인지를 학습하는 것이다. 행동을 취할 때마다 외부 환경에서 보상(Reward)이 주어지는데, 이러한 보상을 최대화 하는 방향으로 학습이 진행된다. 그리고 이러한 보상은 행동을 취한 즉시 주어지지 않을 수도 있다(지연된 보상). 이 때문에 문제의 난이도가 앞의 두개에 비해 대폭 상승한다. 대표적으로 게임 인공지능을 만드는 것을 생각해볼 수 있다. 체스에서 현재 나와 적의 말의 배치가 State가 되고 여기서 어떤 말을 어떻게 움직일지가 Action이 된다. 상대 말을 잡게 되면 보상이 주어지는데, 상대 말이 멀리 떨어져 이동할 때 까지의 시간이 필요할 수 있으므로, 상대 말을 잡는 보상은 당장 주어지지 않는 경우도 생길 수 있다 (지연된 보상). 따라서 강화학습에서는 당장의 보상값이 조금은 적더라도, 나중에 얻을 값을 포함한 보상값의 총 합이 최대화되도록 Action을 선택해야 하며, 게다가 행동하는 플레이어는 어떤 행동을 해야 저 보상값의 합이 최대화되는지 모르기 때문에, 미래를 고려하면서 가장 좋은 선택이 뭔지 Action을 여러 방식으로 수행하며 고민해야 한다. 좋은 선택이 뭔지 Action을 찾는 것을 탐색, 지금까지 나온 지식을 기반으로 가장 좋은 Action을 찾아 그것을 수행하는 것을 활용한다고 하여, 강화학습을 푸는 알고리즘은 이 둘 사이의 균형을 어떻게 잡아야 할지에 초점을 맞춘다. 위 방법들과는 다르게 실시간으로 학습을 진행하는게 일반적이다.


    요약 : 정답이 아니라 포상을 획득한다. --> 포상을 최대화 하는 정책으로 학습 . 이는 당장의 포상 뿐만이 아니라 최종 결과의 포상을 더 우선시한다. (친구한테 들은 이야기인데, 알파고는 70%로 큰 점수차로 이길 확률보다 99%로 1점차이로 이길 확률을 더 크게 본다고 한다. 이게 강화학습적인 관점 아닐까)


- 데이터마이닝 : 
     __위키백과 출처__ : 데이터 마이닝(data mining)은 대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 패턴을 찾아 내는 것이다. 다른 말로는KDD(데이터베이스 속의 지식 발견, knowledge-discovery in databases)라고도 일컫는다. [1]


- 딥러닝 : (딥러닝 부터 조금 어려워지네요 ) 

     __위키백과 출처__ : 딥 러닝[1](영어: deep learning)은 여러 비선형 변환기법의 조합을 통해 높은 수준의 추상화(abstractions, 다량의 데이터나 복잡한 자료들 속에서 핵심적인 내용 또는 기능을 요약하는 작업)를 시도하는 기계학습(machine learning) 알고리즘의 집합[2] 으로 정의 되며, 큰틀에서 사람의 사고방식을 컴퓨터에게 가르치는 기계학습의 한 분야라고 이야기 할 수 있다.
어떠한 데이터가 있을 때 이를 컴퓨터가 알아 들을 수 있는 형태(예를 들어 이미지의 경우는 픽셀정보를 열벡터로 표현하는 등)로 표현(representation)하고 이를 학습에 적용하기 위해 많은 연구(어떻게 하면 더 좋은 표현기법을 만들고 또 어떻게 이것들을 학습할 모델을 만들지에 대한)가 진행되고 있으며, 이러한 노력의 결과로 deep neural networks, convolutional deep neural networks, deep belief networks와 같은 다양한 딥 러닝 기법들이 컴퓨터비젼, 음성인식, 자연어처리, 음성/신호처리 등의 분야에 적용되어 최첨단의 결과들을 보여주고 있다.



    __나무위키 출처__ :  MLP ( 말그대로 여러개의 Perceptron 층(Layer)들을 중첩시켜 만든 모델을 뜻한다. )를 포함한 다양한 종류의 인공신경망을 "복합적으로", "아주 깊게 (deep) 쌓는"것을 가리킨다. 

딥러닝의 가장 큰 특징은 무식하게 모델의 부피를 키우고, 데이터를 쏟아부으면 그만큼의 성능이 향상된다는 점이다..[3] 실례로 네이버의 Deview2013에서 딥러닝에 대한 세션이 있었는데 딥러닝 이전과 이후를 각각 청동기 시대와 철기 시대에 비유할정도로 딥러닝을 높게 평가했다.  다만, 어떤 사람들은 딥러닝을 다른 기계학습과 동떨어진, 마법의 기술처럼 착각하는 경향이 있는데, 사실 많은 기계학습 알고리즘이 딥러닝의 한 종류라고 볼 수 있다. 



    요약 : 수 많은 데이터 속에서 핵심적인 내용 또는 기능을 요약 하는 머신러닝 (기계학습) 알고리즘의 집합



- 인공신경망 : 생물학의 신경망을 본떠서 만들었다. --> 데이터를 통해 학습 능력을 가지게 한다. 

     __위키백과 출처__ : 기계학습 그리고 인지과학에서의 인공신경망(人工神經網, artificial neural network 아티피셜 뉴럴 네트워크[*])은 생물학의 신경망(동물의 중추신경계, 특히 뇌)에서 영감을 얻은 통계학적 학습 알고리즘이다. 인공신경망은 시냅스의 결합으로 네트워크를 형성한 인공 뉴런(노드)이 학습을 통해 시냅스의 결합 세기를 변화시켜, 문제 해결 능력을 가지는 모델 전반을 가리킨다. 좁은 의미에서는 오차역전파법을 이용한 다층 퍼셉트론을 가리키는 경우도 있지만, 이것은 잘못된 용법으로, 인공신경망은 이에 국한되지 않는다.
인공신경망에는 교사 신호(정답)의 입력에 의해서 문제에 최적화되어 가는 교사 학습과 교사 신호를 필요로 하지 않는 비교사 학습이 있다. 명확한 해답이 있는 경우에는 교사 학습이, 데이터 클러스터링에는 비교사 학습이 이용된다. 인공신경망은 많은 입력들에 의존하면서 일반적으로 베일에 싸인 함수를 추측하고 근사치를 낼 경우 사용한다. 일반적으로 입력으로부터 값을 계산하는 뉴런 시스템의 상호연결로 표현되고 적응성이 있어 패턴인식과 같은 기계학습을 수행할 수 있다.

예를들면, 필기체 인식을 위한 신경망은 입력 뉴런의 집합으로 정의되며 이들은 입력 이미지의 픽셀에 의해 활성화된다. 함수의 변형과 가중치가(이들은 신경망을 만든 사람이 결정한다.) 적용된 후 해당 뉴런의 활성화는 다른 뉴런으로 전달된다. 이러한 처리는 마지막 출력 뉴런이 활성화될 때까지 반복되며 이것은 어떤 문자를 읽었는 지에 따라 결정된다.

다른 기계학습과 같이-데이터로부터 학습하는- 신경망은 일반적으로 규칙기반 프로그래밍으로 풀기 어려운 컴퓨터 비전 또는 음성 인식과 같은 다양한 범위의 문제를 푸는데 이용된다.



    __나무위키 출처__ :  가상의 뉴런을 수학적으로 모
